{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BgrFhzziJQHL9aW4IFxt-HmQb0vRikvw",
      "authorship_tag": "ABX9TyPqHUkm+aYb/PbTPYAvrdvh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonaBaron/TensorFlow/blob/main/06_transfer_learning_tensorflow_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzhutC4CCcrS"
      },
      "source": [
        "# Transfer Learning with TensorFlow Part 3: Scaling up (Food Vision mini)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3TQX1ufCpgx",
        "outputId": "f764c0aa-79cf-4240-ac66-c7bf1ff37e36"
      },
      "source": [
        "# GPU?\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysedop3jDMYk"
      },
      "source": [
        "## Creating helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43impjRADajW",
        "outputId": "9a483306-ac6f-4eb4-9d34-d78c104d5dea"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-18 16:41:30--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-18 16:41:30 (93.7 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_3vx0dPDkus"
      },
      "source": [
        "# Import functions\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TheYt7yZD249"
      },
      "source": [
        "## Less data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2agGtGeD9md",
        "outputId": "7fe8a7da-cb36-4a82-e87e-7cd89c7aafa9"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
        "unzip_data(\"101_food_classes_10_percent.zip\")\n",
        "\n",
        "train_dir = \"101_food_classes_10_percent/train/\"\n",
        "test_dir = \"101_food_classes_10_percent/test/\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-18 16:41:37--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.163.207, 142.251.167.207, 142.251.179.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.163.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip’\n",
            "\n",
            "101_food_classes_10 100%[===================>]   1.51G   185MB/s    in 15s     \n",
            "\n",
            "2025-01-18 16:41:52 (102 MB/s) - ‘101_food_classes_10_percent.zip’ saved [1625420029/1625420029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkbM6Ih8EU-P",
        "outputId": "3921c73f-b89c-44a0-aaab-fd2174df0e97"
      },
      "source": [
        "# How many images?\n",
        "walk_through_dir(\"101_food_classes_10_percent\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '101_food_classes_10_percent'.\n",
            "There are 101 directories and 0 images in '101_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/strawberry_shortcake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/club_sandwich'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/cheese_plate'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/samosa'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/fish_and_chips'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/creme_brulee'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/tuna_tartare'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/nachos'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/crab_cakes'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/clam_chowder'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/foie_gras'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/beet_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/oysters'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/french_fries'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/dumplings'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/tacos'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/falafel'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/bread_pudding'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chicken_quesadilla'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/mussels'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/lobster_bisque'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/beef_tartare'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/lobster_roll_sandwich'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/seaweed_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/lasagna'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/cup_cakes'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/beignets'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/baklava'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pad_thai'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/takoyaki'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/paella'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/prime_rib'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pork_chop'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/hummus'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/greek_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/ceviche'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/shrimp_and_grits'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/baby_back_ribs'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/risotto'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/escargots'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/french_toast'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/poutine'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chocolate_cake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/red_velvet_cake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/waffles'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/gyoza'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/bibimbap'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/macarons'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/macaroni_and_cheese'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/tiramisu'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/gnocchi'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/spaghetti_carbonara'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/frozen_yogurt'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/beef_carpaccio'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/eggs_benedict'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/panna_cotta'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/sashimi'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/guacamole'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/apple_pie'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/donuts'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/onion_rings'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/french_onion_soup'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pulled_pork_sandwich'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/bruschetta'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pancakes'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/breakfast_burrito'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pho'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/scallops'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/hot_dog'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/miso_soup'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/caprese_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/churros'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/caesar_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/deviled_eggs'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/garlic_bread'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/hot_and_sour_soup'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/spaghetti_bolognese'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/filet_mignon'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/ravioli'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/edamame'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/spring_rolls'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/cheesecake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/croque_madame'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/omelette'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chocolate_mousse'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/fried_calamari'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/cannoli'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/carrot_cake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/huevos_rancheros'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/peking_duck'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/grilled_cheese_sandwich'.\n",
            "There are 101 directories and 0 images in '101_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/strawberry_shortcake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/club_sandwich'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/cheese_plate'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/samosa'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/fish_and_chips'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/creme_brulee'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/tuna_tartare'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/nachos'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/crab_cakes'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/clam_chowder'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/foie_gras'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/beet_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/oysters'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/french_fries'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/dumplings'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/tacos'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/falafel'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/bread_pudding'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chicken_quesadilla'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/mussels'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/lobster_bisque'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/beef_tartare'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/lobster_roll_sandwich'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/seaweed_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/lasagna'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/cup_cakes'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/beignets'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/baklava'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pad_thai'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/takoyaki'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/paella'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/prime_rib'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pork_chop'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/hummus'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/greek_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/ceviche'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/shrimp_and_grits'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/baby_back_ribs'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/risotto'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/escargots'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/french_toast'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/poutine'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chocolate_cake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/red_velvet_cake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/waffles'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/gyoza'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/bibimbap'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/macarons'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/macaroni_and_cheese'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/tiramisu'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/gnocchi'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/spaghetti_carbonara'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/frozen_yogurt'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/beef_carpaccio'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/eggs_benedict'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/panna_cotta'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/sashimi'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/guacamole'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/apple_pie'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/donuts'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/onion_rings'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/french_onion_soup'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pulled_pork_sandwich'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/bruschetta'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pancakes'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/breakfast_burrito'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pho'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/scallops'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/hot_dog'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/miso_soup'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/caprese_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/churros'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/caesar_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/deviled_eggs'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/garlic_bread'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/hot_and_sour_soup'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/spaghetti_bolognese'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/filet_mignon'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/ravioli'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/edamame'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/spring_rolls'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/cheesecake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/croque_madame'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/omelette'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chocolate_mousse'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/fried_calamari'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/cannoli'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/carrot_cake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/huevos_rancheros'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/peking_duck'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/grilled_cheese_sandwich'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaFm5YqFEiCf",
        "outputId": "b390947b-764b-46db-b95b-577077155abf"
      },
      "source": [
        "# Setup data inputs\n",
        "import tensorflow as tf\n",
        "IMG_SIZE = (224, 224)\n",
        "train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                                label_mode=\"categorical\",\n",
        "                                                                                image_size=IMG_SIZE)\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                image_size=IMG_SIZE,\n",
        "                                                                shuffle=False) # don't shuffle data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7575 files belonging to 101 classes.\n",
            "Found 25250 files belonging to 101 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FajNBzelFX1l"
      },
      "source": [
        "## Train a model with transfer learning on 10% of data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ8shUEUGyy5"
      },
      "source": [
        "# Create checkpoint callback\n",
        "checkpoint_path = \"101_classes_10_percent_data_model_checkpoint.weights.h5\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                         save_weights_only=True,\n",
        "                                                         monitor=\"val_accuracy\",\n",
        "                                                         save_best_only=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkBm9UYuHcq9"
      },
      "source": [
        "# Data augmentation\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "data_augmentation = Sequential([\n",
        "  layers.RandomFlip(\"horizontal\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "  layers.RandomHeight(0.2),\n",
        "  layers.RandomWidth(0.2),\n",
        "  layers.RandomZoom(0.2),\n",
        "  # layers.Rescaling(1/255.)  rescale images ,for models like ResNet50\n",
        "], name=\"data_augmentation\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PJIA4HWIK6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863d9dce-a456-46f7-fc4f-8d9d0dd55e58"
      },
      "source": [
        "# Setup the base model\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Setup model\n",
        "inputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D(name=\"global_avg_pool_layer\")(x)\n",
        "outputs = layers.Dense(len(train_data_all_10_percent.class_names), activation=\"softmax\", name=\"output_layer\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "5BuCy7lcKq4y",
        "outputId": "ee4316b6-f563-4bb2-fe3d-c69a10093a8f"
      },
      "source": [
        "# Summary\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)    │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_avg_pool_layer                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │         \u001b[38;5;34m129,381\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_avg_pool_layer                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,178,952\u001b[0m (15.94 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,178,952</span> (15.94 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,381\u001b[0m (505.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> (505.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_xCPNAYLJZ1",
        "outputId": "5f66084c-fb1b-4131-d329-1c5aa3037efe"
      },
      "source": [
        "# Compile\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit\n",
        "history_all_classes_10_percent = model.fit(train_data_all_10_percent,\n",
        "                                           epochs=5,\n",
        "                                           validation_data=test_data,\n",
        "                                           validation_steps=int(0.15 * len(test_data)), # 15% of test data\n",
        "                                           callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m111/237\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:07\u001b[0m 3s/step - accuracy: 0.0634 - loss: 4.3932"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBBrkBuvMsZs"
      },
      "source": [
        "# Evaluate\n",
        "feature_extraction_results = model.evaluate(test_data)\n",
        "feature_extraction_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh2TomuUOUyL"
      },
      "source": [
        "# Plot loss curves\n",
        "plot_loss_curves(history_all_classes_10_percent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y0f8onOPEpk"
      },
      "source": [
        "Looks like our model is overfiting, bc the lines should be very similar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KFFNYoZPBIx"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD2VX5hPQDMD"
      },
      "source": [
        "# Unfreeze all of the layers in model\n",
        "base_model.trainable = True\n",
        "\n",
        "# freeze every layer except the last 5\n",
        "for layer in base_model.layers[:-5]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwsM69ngQd8X"
      },
      "source": [
        "# compile model with lower learning\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBP2v4ARXF9"
      },
      "source": [
        "# What layers are trainable?\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTLWh0QYRbkj"
      },
      "source": [
        "# To look deeper\n",
        "for layer_number, layer in enumerate(model.layers[2].layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-0VxIqxR1HI"
      },
      "source": [
        "# 5 more epochs (5 + 5 = 10)\n",
        "fine_tune_epochs = 10\n",
        "\n",
        "# Fit (Fine-tune)\n",
        "history_all_classes_10_percent_fine_tune = model.fit(train_data_all_10_percent,\n",
        "                                                     epochs=fine_tune_epochs,\n",
        "                                                     validation_data=test_data,\n",
        "                                                     validation_steps=int(0.15 * len(test_data)),\n",
        "                                                     initial_epoch=history_all_classes_10_percent.epoch[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx2ExyDtTWha"
      },
      "source": [
        "# Evaluate\n",
        "all_classes_10_percent_fine_tune_results = model.evaluate(test_data)\n",
        "all_classes_10_percent_fine_tune_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy_0EqkOVB77"
      },
      "source": [
        "# Compare histories\n",
        "compare_historys(original_history=history_all_classes_10_percent,\n",
        "                 new_history=history_all_classes_10_percent_fine_tune,\n",
        "                 initial_epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVVUSGwLV4kX"
      },
      "source": [
        "## Save and load\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PupsmM5MWuck"
      },
      "source": [
        "# Save our model\n",
        "model.save(\"drive/MyDrive/tensorflow_course/101_food_classes_10_percent_saved_big_dog_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJoqWXQzXGNc"
      },
      "source": [
        "# Load model\n",
        "loaded_model = tf.keras.models.load_model(\"drive/MyDrive/tensorflow_course/101_food_classes_10_percent_saved_big_dog_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngrnDjM0XQe6"
      },
      "source": [
        "# Evaluate loaded model and compare performance to pre-saved model\n",
        "loaded_model_results = loaded_model.evaluate(test_data)\n",
        "loaded_model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMas7jIFXguR"
      },
      "source": [
        "# The results from our loaded_model (above) should be very similar to the results below\n",
        "all_classes_10_percent_fine_tune_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jloR8YVCXmcV"
      },
      "source": [
        "## Evaluating the performance of the big dog model across all different classes\n",
        "\n",
        "Let's make some predictions, visualize them and then later find out which predictions were the \"most\" wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCFnpshlaW7d"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Download pretrained model (one that was prepared earlier, so all predictions are similar)\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y97GaBD5akk1"
      },
      "source": [
        "unzip_data(\"/content/06_101_food_class_10_percent_saved_big_dog_model.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOvXY4L6arpD"
      },
      "source": [
        "# Load in saved model\n",
        "model = tf.keras.models.load_model(\"/content/06_101_food_class_10_percent_saved_big_dog_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQVP9wCza-_W"
      },
      "source": [
        "# Evaluate loaded model (the one we just downloaded on test data)\n",
        "results_downloaded_model = model.evaluate(test_data)\n",
        "results_downloaded_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA4jqA3GcU6L"
      },
      "source": [
        "## Making predictions with our trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb3a_DoAdL3q"
      },
      "source": [
        "# Make predictions with model\n",
        "preds_probs = model.predict(test_data, verbose=1) # set verbosity to see how long is left"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOz69x8QdoqO"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msQMSr90eLN-"
      },
      "source": [
        "# How many predictions are there?\n",
        "len(preds_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_V2RxuBeYbl"
      },
      "source": [
        "# What's the shape of our predictions?\n",
        "preds_probs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ct9IVZpejr4"
      },
      "source": [
        "# Let's see what the first 10 predictions look like\n",
        "preds_probs[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oTSp4U1eykD"
      },
      "source": [
        "# What does the first prediction probability array look like?\n",
        "preds_probs[0], len(preds_probs[0]), sum(preds_probs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZjRlDeAfScZ"
      },
      "source": [
        "Our model outputs a prediction probability array (with N number of variables, where N is the number of classes) for each sample passed to the predict method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrLwfds8e8Bi"
      },
      "source": [
        "# We get one prediction probability per class (in our case there's 101 prediction probabilities)\n",
        "print(f\"Number of prediction probabilities for sample 0: {len(preds_probs[0])}\")\n",
        "print(f\"What prediction probability sample 0 looks like:\\n {preds_probs[0]}\")\n",
        "print(f\"The class with the highest predicted probability by the model for sample 0: {preds_probs[0].argmax()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C6OW2ZigIeO"
      },
      "source": [
        "# Get the pred classes of each label\n",
        "pred_classes = preds_probs.argmax(axis=1)\n",
        "\n",
        "# How do they look?\n",
        "pred_classes[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNRHYn7ogXxu"
      },
      "source": [
        "# How many pred classes do we have?\n",
        "len(pred_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEagICa6hDqz"
      },
      "source": [
        "Now we've got a predictions array of all of our model's predictions, to evaluate them, we need to compare them to the original test dataset labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47BhszLbgbFf"
      },
      "source": [
        "# To get our test labels we need to unravel our test_data BatchDataset\n",
        "y_labels = []\n",
        "for images, labels in test_data.unbatch():\n",
        "  y_labels.append(labels.numpy().argmax()) # currently test labels look like: [0, 0, 0, 1, .... 0, 0], we want the index value where the \"1\" occurs\n",
        "y_labels[:10] # look at the first 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWBLPBZmiISu"
      },
      "source": [
        "# How many y_labels are there?\n",
        "len(y_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhxE9dFRhKKu"
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zgya6jxhYa5"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO_8CTW6hetz"
      },
      "source": [
        "## Evaluating our model's predictions\n",
        "\n",
        "One way to check that our model's predictions array (`pred_classes`) is in the same order as our test labels array (`y_labels`) is to find the accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr59fTr1jF2g"
      },
      "source": [
        "results_downloaded_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EznPAU2ajH3o"
      },
      "source": [
        "# Let's try scikit-learn's accuracy score function and see what it comes up with\n",
        "from sklearn.metrics import accuracy_score\n",
        "sklearn_accuracy = accuracy_score(y_true=y_labels,\n",
        "                                  y_pred=pred_classes)\n",
        "sklearn_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Yqf3v7jo_6"
      },
      "source": [
        "# Does this metric come close to our model's evaluate results\n",
        "import numpy as np\n",
        "np.isclose(results_downloaded_model[1], sklearn_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bGyMzqxkAkJ"
      },
      "source": [
        "## Let's get visual: making a confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W730Mc8hkojO"
      },
      "source": [
        "from helper_functions import make_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p6KSRfsk7Gs"
      },
      "source": [
        "# Get a list of class names\n",
        "class_names = test_data.class_names\n",
        "class_names[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0pMjx3BmDIW"
      },
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# We need to make some changes to our make_confusion_matrix function to ensure the x-labels print vertically\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  ### Changed (plot x-labels vertically) ###\n",
        "  plt.xticks(rotation=70, fontsize=text_size)\n",
        "  plt.yticks(fontsize=text_size)\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FMsjQnuklam"
      },
      "source": [
        "make_confusion_matrix(y_true=y_labels,\n",
        "                      y_pred=pred_classes,\n",
        "                      classes=class_names,\n",
        "                      figsize=(100, 100),\n",
        "                      text_size=20,\n",
        "                      savefig=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjUbrjlQoUJw"
      },
      "source": [
        "## Let's keep the evaluation train going, time for a classification report\n",
        "\n",
        "Scikit-learn has a helpful function for acquiring many different classification metrics per class (e.g. precision, recall and F1) called [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), let's try it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzUvJtEronRy"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true=y_labels,\n",
        "                            y_pred=pred_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo0OBrhUpqLC"
      },
      "source": [
        "The numbers above give a great class-by-class evaluation of our model's predictions but with so many classes, they're quite hard to understand.\n",
        "\n",
        "How about we create a visualization to get a better understanding?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjRcWHwApBHd"
      },
      "source": [
        "# Get a dictionary of the classification report\n",
        "classification_report_dict = classification_report(y_labels, pred_classes, output_dict=True)\n",
        "classification_report_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEL8oi4DqUHg"
      },
      "source": [
        "Let's plot all of our classes F1-scores..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkzXg4akq9QU"
      },
      "source": [
        "class_names[98]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZk-M3p8rDaC"
      },
      "source": [
        "classification_report_dict[\"99\"][\"f1-score\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvNXVaFeqMhu"
      },
      "source": [
        "# Create empty dictionary\n",
        "class_f1_scores = {}\n",
        "# Loop through classification report dictionary items\n",
        "for k, v in classification_report_dict.items():\n",
        "  if k == \"accuracy\": # stop once we get to accuracy key\n",
        "    break\n",
        "  else:\n",
        "    # Add class names and f1-scores to new dictionary\n",
        "    class_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n",
        "class_f1_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puy5a-zFrKrj"
      },
      "source": [
        "# Trun f1-scores into dataframe for visualization\n",
        "import pandas as pd\n",
        "f1_scores = pd.DataFrame({\"class_names\": list(class_f1_scores.keys()),\n",
        "                          \"f1-score\": list(class_f1_scores.values())}).sort_values(\"f1-score\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsqMF9yRr3N8"
      },
      "source": [
        "# What does our dataframe look like?\n",
        "f1_scores[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dljI7ke1r4Io"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 25))\n",
        "scores = ax.barh(range(len(f1_scores)), f1_scores[\"f1-score\"].values) # get f1-score values\n",
        "ax.set_yticks(range(len(f1_scores)))\n",
        "ax.set_yticklabels(f1_scores[\"class_names\"])\n",
        "ax.set_xlabel(\"F1-score\")\n",
        "ax.set_title(\"F1-scores for 101 Different Food Classes (predicted by Food Vision mini)\")\n",
        "ax.invert_yaxis(); # reverse the order of our plot\n",
        "\n",
        "# Challenge: add values to the end of each bar of what the actual f1-score is\n",
        "# (hint: use the \"autolabel\" function from here: https://matplotlib.org/2.0.2/examples/api/barchart_demo.html)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVnrUcM7tyvs"
      },
      "source": [
        "> 🛠 **Exercise:** Try visualizing some of the most poorly predicted classes (e.g. `apple_pie`, `pork_chip`), do you notice any trends among them? Why might our model be having trouble with them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAuQkDhXuPCr"
      },
      "source": [
        "## Visualizing predictions on test images\n",
        "\n",
        "Now, this is the real test, how does our model go on food images not even in our test dataset (images of our own, we'll see this later on).\n",
        "\n",
        "To visualize our model's predictions on our own images, we'll need a function to load and preprocess images, specifically it will need to:\n",
        "* Read in a target image filepath using tf.io.read_file()\n",
        "* Turn the image into a Tensor using tf.io.decode_image()\n",
        "* Resize the image tensor to be the same size as the images our model has trained on using tf.image.resize()\n",
        "* Scale the image to get all of the pixel values between 0 & 1 (if necessary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi1o6B7Ru8Ku"
      },
      "source": [
        "# Create a function to load and prepare images\n",
        "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  specified shape (img_shape, img_shape, color_channels=3).\n",
        "\n",
        "  Args:\n",
        "    filename (str): path to target image\n",
        "    image_shape (int): height/width dimension of target image size\n",
        "    scale (bool): scale pixel values from 0-255 to 0-1 or not\n",
        "\n",
        "  Returns:\n",
        "    Image tensor of shape (img_shape, img_shape, 3)\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode image into tensor\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "\n",
        "  # Scale? Yes/no\n",
        "  if scale:\n",
        "    # rescale the image (get all values between 0 and 1)\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img # don't need to rescale images for EfficientNet models in TensorFlow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEA9CCt6x1j8"
      },
      "source": [
        "Now we've got a function to load and prepare target images, let's now write some code to visualize images, their target label and our model's predictions.\n",
        "\n",
        "Specifically, we'll write some code to:\n",
        "1. Load a few random images from the test dataset\n",
        "2. Make predictions on the loaded images\n",
        "3. Plot the original image(s) along with the model's predictions, prediction probability and truth label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-daQ2LVzrei"
      },
      "source": [
        "train_data_all_10_percent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrgRv6QRxyKu"
      },
      "source": [
        "# Make preds on a series of random images\n",
        "import os\n",
        "import random\n",
        "\n",
        "plt.figure(figsize=(17, 10))\n",
        "for i in range(3):\n",
        "  # Choose random image(s) from random class(es)\n",
        "  class_name = random.choice(class_names)\n",
        "  filename = random.choice(os.listdir(test_dir + \"/\" + class_name))\n",
        "  filepath = test_dir + class_name + \"/\" + filename\n",
        "\n",
        "  # Load the image and make predictions\n",
        "  img = load_and_prep_image(filepath, scale=False)\n",
        "  img_expanded = tf.expand_dims(img, axis=0)\n",
        "  # print(img_expanded.shape)\n",
        "  pred_prob = model.predict(img_expanded) # get prediction probabilities array\n",
        "  pred_class = class_names[pred_prob.argmax()] # get highest prediction probability index and match it class_names list\n",
        "  # print(pred_prob)\n",
        "  # print(pred_class)\n",
        "\n",
        "  # Plot the image(s)\n",
        "  plt.subplot(1, 3, i+1)\n",
        "  # print(img)\n",
        "  plt.imshow(img/225.)\n",
        "  if class_name == pred_class: # if predicted class matches truth class, make text green\n",
        "    title_color = \"g\"\n",
        "  else:\n",
        "    title_color = \"r\"\n",
        "  plt.title(f\"actual: {class_name}, pred: {pred_class}, prob: {pred_prob.max():.2f}\", c=title_color)\n",
        "  plt.axis(False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAI0U7DjyngG"
      },
      "source": [
        "## Finding the most wrong predictions\n",
        "\n",
        "To find out where our model is most wrong, let's write some code to find out the following:\n",
        "1. Get all of the image file paths in the test dataset using [list_files()](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#list_files) method\n",
        "2. Create a pandas DataFrame of the image filepaths, ground truth labels, predicted classes (from our model), max prediction probabilities, prediction class names, ground truth class names.\n",
        "3. Use our DataFrame to find all the wrong predictions (where the ground truth label doesn't match the prediction).\n",
        "4. Sort the DataFrame based on wrong predictions (have the highest prediction probability predictions at the top).\n",
        "5. Visualize the images with the highest prediction probabilities but have the wrong prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfWy1uJU28I-"
      },
      "source": [
        "# 1. Get all of the image file paths in the test dataset\n",
        "filepaths = []\n",
        "for filepath in test_data.list_files(\"/content/101_food_classes_10_percent/test/*/*.jpg\",\n",
        "                                     shuffle=False):\n",
        "  filepaths.append(filepath.numpy())\n",
        "filepaths[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPaxci3c5lAq"
      },
      "source": [
        "# 2. Create a DataFrame of different parameters for each of our test images\n",
        "import pandas as pd\n",
        "pred_df = pd.DataFrame({\"img_path\": filepaths,\n",
        "                        \"y_true\": y_labels,\n",
        "                        \"y_pred\": pred_classes,\n",
        "                        \"pred_conf\": preds_probs.max(axis=1), # get the maximum prediction probability value\n",
        "                        \"y_true_classname\": [class_names[i] for i in y_labels],\n",
        "                        \"y_pred_classname\": [class_names[i] for i in pred_classes]})\n",
        "pred_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekwqkRtB6AdF"
      },
      "source": [
        "# 3. Find out in our DataFrame which predictions are wrong\n",
        "pred_df[\"pred_correct\"] = pred_df[\"y_true\"] == pred_df[\"y_pred\"]\n",
        "pred_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmlx-p8C68uA"
      },
      "source": [
        "# 4. Sort our DataFrame to have most wrong predictions at the top\n",
        "top_100_wrong = pred_df[pred_df[\"pred_correct\"] == False].sort_values(\"pred_conf\", ascending=False)[:100]\n",
        "top_100_wrong.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJnvfOUr7VnR"
      },
      "source": [
        "# 5. Visualize the test data samples which have the wrong prediction but highest pred probability\n",
        "images_to_view = 9\n",
        "start_index = 20\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, row in enumerate(top_100_wrong[start_index:start_index+images_to_view].itertuples()):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  img = load_and_prep_image(row[1], scale=False)\n",
        "  _, _, _, _, pred_prob, y_true_classname, y_pred_classname, _ = row # only interested in a few parameters of each row\n",
        "  plt.imshow(img/255.)\n",
        "  plt.title(f\"actual: {y_true_classname}, pred: {y_pred_classname} \\nprob: {pred_prob}\")\n",
        "  plt.axis(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOdLCmxz8kBz"
      },
      "source": [
        "## Test out the big dog model on our own custom images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX7y0lui_HY1"
      },
      "source": [
        "# Get custom images\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/custom_food_images.zip\n",
        "\n",
        "unzip_data(\"custom_food_images.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPXHTgcg_dPh"
      },
      "source": [
        "# Get the custom food images filepaths\n",
        "custom_food_images = [\"custom_food_images/\" + img_path for img_path in os.listdir(\"custom_food_images\")]\n",
        "custom_food_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d40MfMeQ_tLY"
      },
      "source": [
        "# Make predictions on and plot custom food images\n",
        "for img in custom_food_images:\n",
        "  img = load_and_prep_image(img, scale=False) # don't need to scale for our EfficientNetB0 model\n",
        "  pred_prob = model.predict(tf.expand_dims(img, axis=0)) # make prediction on image with shape [1, 224, 224, 3] (same shape as model was trained on)\n",
        "  pred_class = class_names[pred_prob.argmax()] # get the index with the highet prediction probability\n",
        "  # Plot the appropriate information\n",
        "  plt.figure()\n",
        "  plt.imshow(img/225.)\n",
        "  plt.title(f\"pred: {pred_class}, prob: {pred_prob.max():.2f}\")\n",
        "  plt.axis(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U90PMMuyYYES"
      },
      "source": [
        "See full course materials (including exercises and extra-curriculum on GitHub): https://github.com/mrdbourke/tensorflow-deep-learning"
      ]
    }
  ]
}